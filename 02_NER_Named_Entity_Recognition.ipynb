{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "02-NER-Named-Entity-Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khuloodnasher/Name-Entity-Recognition-NER-/blob/main/02_NER_Named_Entity_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "qqVpRa3mTl7Z"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Named-Entity-Recognition-(NER)\" data-toc-modified-id=\"Named-Entity-Recognition-(NER)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Named Entity Recognition (NER)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Entity-annotations\" data-toc-modified-id=\"Entity-annotations-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Entity annotations</a></span></li><li><span><a href=\"#NER-Tags\" data-toc-modified-id=\"NER-Tags-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>NER Tags</a></span></li><li><span><a href=\"#Adding-a-Named-Entity-to-a-Span\" data-toc-modified-id=\"Adding-a-Named-Entity-to-a-Span-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Adding a Named Entity to a Span</a></span></li><li><span><a href=\"#Adding-Named-Entities-to-All-Matching-Spans\" data-toc-modified-id=\"Adding-Named-Entities-to-All-Matching-Spans-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Adding Named Entities to All Matching Spans</a></span></li><li><span><a href=\"#Counting-Entities\" data-toc-modified-id=\"Counting-Entities-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Counting Entities</a></span></li><li><span><a href=\"#Problem-with-Line-Breaks\" data-toc-modified-id=\"Problem-with-Line-Breaks-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><font color=\"blue\">Problem with Line Breaks</font></a></span><ul class=\"toc-item\"><li><span><a href=\"#However,-there-is-a-simple-fix-that-can-be-added-to-the-nlp-pipeline:\" data-toc-modified-id=\"However,-there-is-a-simple-fix-that-can-be-added-to-the-nlp-pipeline:-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span><font color=\"blue\">However, there is a simple fix that can be added to the nlp pipeline:</font></a></span></li></ul></li><li><span><a href=\"#Noun-Chunks\" data-toc-modified-id=\"Noun-Chunks-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Noun Chunks</a></span><ul class=\"toc-item\"><li><span><a href=\"#noun_chunks-components:\" data-toc-modified-id=\"noun_chunks-components:-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span><code>noun_chunks</code> components:</a></span></li><li><span><a href=\"#Doc.noun_chunks-is-a--generator-function\" data-toc-modified-id=\"Doc.noun_chunks-is-a--generator-function-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span><code>Doc.noun_chunks</code> is a  generator function</a></span></li></ul></li><li><span><a href=\"#Next-up:-Visualizing-NER\" data-toc-modified-id=\"Next-up:-Visualizing-NER-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Next up: Visualizing NER</a></span></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OejUnc5Tl7Z"
      },
      "source": [
        "___\n",
        "\n",
        "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R99RksTUTl7Z"
      },
      "source": [
        "# Named Entity Recognition (NER)\n",
        "spaCy has an **'ner'** pipeline component that identifies token spans fitting a predetermined set of named entities. These are available as the `ents` property of a `Doc` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.758562Z",
          "start_time": "2020-12-06T02:23:50.667190Z"
        },
        "id": "PlT5NNphTl7Z"
      },
      "source": [
        "# Perform standard imports\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.763809Z",
          "start_time": "2020-12-06T02:23:50.649Z"
        },
        "id": "lps0mGXWTl7a"
      },
      "source": [
        "# Write a function to display basic entity info:\n",
        "def show_ents(doc):\n",
        "    if doc.ents:\n",
        "        for ent in doc.ents:\n",
        "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
        "    else:\n",
        "        print('No named entities found.')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.766642Z",
          "start_time": "2020-12-06T02:23:50.652Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cge8hqfTl7a",
        "outputId": "aae4cd2a-7ea2-47cf-d604-23419dae5e8c"
      },
      "source": [
        "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Washington - GPE - Countries, cities, states\n",
            "next May - DATE - Absolute or relative dates or periods\n",
            "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbLMDNOATl7a"
      },
      "source": [
        "Here we see tokens combine to form the entities `Washington, DC`, `next May` and `the Washington Monument`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSHuUaVYTl7a"
      },
      "source": [
        "## Entity annotations\n",
        "`Doc.ents` are token spans with their own set of annotations.\n",
        "<table>\n",
        "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
        "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
        "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
        "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.769074Z",
          "start_time": "2020-12-06T02:23:50.656Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIQh6wu7Tl7a",
        "outputId": "0f1effad-b589-4a62-e39e-0af831a22438"
      },
      "source": [
        "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start, ent.end, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 dollars 4 6 20 31 MONEY\n",
            "Microsoft 11 12 53 62 ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz-36VCCTl7a"
      },
      "source": [
        "## NER Tags\n",
        "Tags are accessible through the `.label_` property of an entity.\n",
        "<table>\n",
        "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
        "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
        "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
        "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
        "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
        "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
        "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
        "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
        "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
        "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
        "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
        "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
        "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
        "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
        "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
        "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
        "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
        "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
        "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C0SI9keTl7a"
      },
      "source": [
        "___\n",
        "## Adding a Named Entity to a Span\n",
        "Normally we would have spaCy build a library of named entities by training it on several samples of text.<br>In this case, we only want to add one value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.771483Z",
          "start_time": "2020-12-06T02:23:50.659Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6yf7bsGTl7a",
        "outputId": "80afb215-473c-4467-c2cd-5c171e420900"
      },
      "source": [
        "doc = nlp(u'Tesla to build a U.K. factory for $6 million')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyAygxx-Tl7a"
      },
      "source": [
        "<font color=green>Right now, spaCy does not recognize \"Tesla\" as a company.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.773707Z",
          "start_time": "2020-12-06T02:23:50.661Z"
        },
        "id": "sHNu7qK1Tl7a"
      },
      "source": [
        "from spacy.tokens import Span\n",
        "\n",
        "# Get the hash value of the ORG entity label\n",
        "ORG = doc.vocab.strings[u'ORG']  \n",
        "\n",
        "# Create a Span for the new entity\n",
        "new_ent = Span(doc, 0, 1, label=ORG)\n",
        "\n",
        "# Add the entity to the existing Doc object\n",
        "doc.ents = list(doc.ents) + [new_ent]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WueLHNpnTl7a"
      },
      "source": [
        "<font color=green>In the code above, the arguments passed to `Span()` are:</font>\n",
        "-  `doc` - the name of the Doc object\n",
        "-  `0` - the *start* index position of the span\n",
        "-  `1` - the *stop* index position (exclusive)\n",
        "-  `label=ORG` - the label assigned to our entity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.776533Z",
          "start_time": "2020-12-06T02:23:50.663Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0j1pNjWTl7b",
        "outputId": "86e5b068-5c22-4926-970b-d14121dce125"
      },
      "source": [
        "show_ents(doc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla - ORG - Companies, agencies, institutions, etc.\n",
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1H4XnnaTl7b"
      },
      "source": [
        "___\n",
        "## Adding Named Entities to All Matching Spans\n",
        "What if we want to tag *all* occurrences of \"Tesla\"? In this section we show how to use the PhraseMatcher to identify a series of spans in the Doc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.778031Z",
          "start_time": "2020-12-06T02:23:50.666Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWCGzc4Tl7b",
        "outputId": "6ef8949f-5d3a-4bfe-c4dc-d425a2e31f1a"
      },
      "source": [
        "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
        "          u'If successful, the vacuum cleaner will be our first product.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first - ORDINAL - \"first\", \"second\", etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.779117Z",
          "start_time": "2020-12-06T02:23:50.668Z"
        },
        "id": "oAHKZiOBTl7b"
      },
      "source": [
        "# Import PhraseMatcher and create a matcher object:\n",
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.780469Z",
          "start_time": "2020-12-06T02:23:50.670Z"
        },
        "id": "Y6mVhzhnTl7b"
      },
      "source": [
        "# Create the desired phrase patterns:\n",
        "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
        "phrase_patterns = [nlp(text) for text in phrase_list]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.781768Z",
          "start_time": "2020-12-06T02:23:50.675Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th2ili6iTl7b",
        "outputId": "2efb326c-71ca-4623-dd4b-6a1ef32e844d"
      },
      "source": [
        "# Apply the patterns to our matcher object:\n",
        "matcher.add('newproduct', None, *phrase_patterns)\n",
        "\n",
        "# Apply the matcher to our Doc object:\n",
        "matches = matcher(doc)\n",
        "\n",
        "# See what matches occur:\n",
        "matches"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2689272359382549672, 7, 9), (2689272359382549672, 14, 16)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.783255Z",
          "start_time": "2020-12-06T02:23:50.677Z"
        },
        "id": "OnglQGusTl7b"
      },
      "source": [
        "# Here we create Spans from each match, and create named entities from them:\n",
        "from spacy.tokens import Span\n",
        "\n",
        "PROD = doc.vocab.strings[u'PRODUCT']\n",
        "\n",
        "new_ents = [Span(doc, match[1],match[2],label=PROD) for match in matches]\n",
        "\n",
        "doc.ents = list(doc.ents) + new_ents"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.784443Z",
          "start_time": "2020-12-06T02:23:50.679Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMo5G65fTl7b",
        "outputId": "558b682c-d8fa-41eb-fcb0-3a81b226639b"
      },
      "source": [
        "show_ents(doc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
            "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
            "first - ORDINAL - \"first\", \"second\", etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wN5dM59Tl7b"
      },
      "source": [
        "___\n",
        "## Counting Entities\n",
        "While spaCy may not have a built-in tool for counting entities, we can pass a conditional statement into a list comprehension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.785901Z",
          "start_time": "2020-12-06T02:23:50.682Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPDkt6EeTl7b",
        "outputId": "624b9f32-0c56-4790-9385-95ec4c552a21"
      },
      "source": [
        "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.787503Z",
          "start_time": "2020-12-06T02:23:50.684Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rySAtvITl7b",
        "outputId": "75caf69b-de9e-4ec2-b85d-0defd40dec7f"
      },
      "source": [
        "len([ent for ent in doc.ents if ent.label_=='MONEY'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BwwcmIATl7b"
      },
      "source": [
        "## <font color=blue>Problem with Line Breaks</font>\n",
        "\n",
        "<div class=\"alert alert-info\" style=\"margin: 20px\">There's a <a href='https://github.com/explosion/spaCy/issues/1717'>known issue</a> with <strong>spaCy v2.0.12</strong> where some linebreaks are interpreted as `GPE` entities:</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.789228Z",
          "start_time": "2020-12-06T02:23:50.687Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EiHorNTbTl7b",
        "outputId": "54d16879-f7ca-4f96-9259-ea39286d79e6"
      },
      "source": [
        "spacy.__version__"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.791316Z",
          "start_time": "2020-12-06T02:23:50.689Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPhLqU7uTl7b",
        "outputId": "3a2ba27e-92a2-4635-a83c-e9a153222857"
      },
      "source": [
        "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT57On-0Tl7b"
      },
      "source": [
        "### <font color=blue>However, there is a simple fix that can be added to the nlp pipeline:</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.793625Z",
          "start_time": "2020-12-06T02:23:50.690Z"
        },
        "id": "j6T9onFITl7b"
      },
      "source": [
        "# Quick function to remove ents formed on whitespace:\n",
        "def remove_whitespace_entities(doc):\n",
        "    doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
        "    return doc\n",
        "\n",
        "# Insert this into the pipeline AFTER the ner component:\n",
        "nlp.add_pipe(remove_whitespace_entities, after='ner')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.795858Z",
          "start_time": "2020-12-06T02:23:50.692Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVIRyWiyTl7b",
        "outputId": "de8efcfc-78ac-4097-ccb1-1b5b63002ceb"
      },
      "source": [
        "# Rerun nlp on the text above, and show ents:\n",
        "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSyVYfenTl7b"
      },
      "source": [
        "For more on **Named Entity Recognition** visit https://spacy.io/usage/linguistic-features#101"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs6z2cGhTl7b"
      },
      "source": [
        "___\n",
        "## Noun Chunks\n",
        "`Doc.noun_chunks` are *base noun phrases*: token spans that include the noun and words describing the noun. Noun chunks cannot be nested, cannot overlap, and do not involve prepositional phrases or relative clauses.<br>\n",
        "Where `Doc.ents` rely on the **ner** pipeline component, `Doc.noun_chunks` are provided by the **parser**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjVAJcpcTl7b"
      },
      "source": [
        "### `noun_chunks` components:\n",
        "<table>\n",
        "<tr><td>`.text`</td><td>The original noun chunk text.</td></tr>\n",
        "<tr><td>`.root.text`</td><td>The original text of the word connecting the noun chunk to the rest of the parse.</td></tr>\n",
        "<tr><td>`.root.dep_`</td><td>Dependency relation connecting the root to its head.</td></tr>\n",
        "<tr><td>`.root.head.text`</td><td>The text of the root token's head.</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.798136Z",
          "start_time": "2020-12-06T02:23:50.695Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZKsXWZFTl7b",
        "outputId": "2cf87803-3ad0-4657-fd22-bb5aa226f97b"
      },
      "source": [
        "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
        "\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text+' - '+chunk.root.text+' - '+chunk.root.dep_+' - '+chunk.root.head.text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars - cars - nsubj - shift\n",
            "insurance liability - liability - dobj - shift\n",
            "manufacturers - manufacturers - pobj - toward\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-CxAggwTl7b"
      },
      "source": [
        "### `Doc.noun_chunks` is a  generator function\n",
        "Previously we mentioned that `Doc` objects do not retain a list of sentences, but they're available through the `Doc.sents` generator.<br>It's the same with `Doc.noun_chunks` - lists can be created if needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.800116Z",
          "start_time": "2020-12-06T02:23:50.697Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "2dNMVFZbTl7b",
        "outputId": "78c3cde4-89f5-4d98-e8c4-a511aea02007"
      },
      "source": [
        "len(doc.noun_chunks)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8b52b37c204e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:23:50.801585Z",
          "start_time": "2020-12-06T02:23:50.699Z"
        },
        "id": "SoA38TNwTl7b"
      },
      "source": [
        "len(list(doc.noun_chunks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-06T02:32:52.856381Z",
          "start_time": "2020-12-06T02:32:52.824784Z"
        },
        "id": "dpGZvAhfTl7b"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "# create the text as nlp object\n",
        "my_text=nlp(u\"\"\" My name is Khulood Nasher.I'm living in Los Angeles, California.I'm working at Amazon as NLP \n",
        "specialist since November 9th,2020. Amazon office is 5 miles from house.\n",
        " I'm working 8 hours a day, 40 hours a week in 5 days, Monday-Friday.\n",
        "I finished master degree in Physics from Idaho State University(ISU),Pocatello, Idaho.\n",
        "My annual salary is $78,230. I also finished Data Sciences at Flatiron School.\n",
        "I'm an Arabic native speaker and an English professional.I have 6 siblings. I'm the second between them.  \"\"\")\n",
        "\n",
        "\n",
        "entities=[(i,i.lablel_,i.label) for i in my_text.ents]\n",
        "display.render(my_text,style='ent',jupyter=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na9WXLIeTl7b"
      },
      "source": [
        "For more on **noun_chunks** visit https://spacy.io/usage/linguistic-features#noun-chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7aAga98Tl7b"
      },
      "source": [
        "Great! Now you should be more familiar with both named entities and noun chunks. In the next section we revisit the NER visualizer.\n",
        "## Next up: Visualizing NER"
      ]
    }
  ]
}